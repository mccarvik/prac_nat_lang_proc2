{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypR4NNY7oyEV"
   },
   "source": [
    "#### We need to install the ktrain library. Its a light weight wrapper for keras to help train neural networks. With only a few lines of code it allows you to build models, estimate optimal learning rate, loading and preprocessing text and image data from various sources and much more. More about our approach can be found at [this](https://towardsdatascience.com/bert-text-classification-in-3-lines-of-code-using-keras-264db7e7a358) article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TF5qfV_flTbr",
    "outputId": "b536d10d-767d-4a8d-9cd6-2ea607550b1b"
   },
   "outputs": [],
   "source": [
    "# To install only the requirements of this notebook, uncomment the lines below and run this cell\n",
    "\n",
    "# ===========================\n",
    "\n",
    "# !pip install numpy==1.19.5\n",
    "# !pip install pandas==1.1.5\n",
    "# !pip install ktrain==0.26.3\n",
    "\n",
    "# ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_UN7tuqnlTbs"
   },
   "outputs": [],
   "source": [
    "# To install the requirements for the entire chapter, uncomment the lines below and run this cell\n",
    "\n",
    "# ===========================\n",
    "\n",
    "# try:\n",
    "#     import google.colab\n",
    "#     !curl  https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch4/ch4-requirements.txt | xargs -n 1 -L 1 pip install\n",
    "# except ModuleNotFoundError:\n",
    "#     !pip install -r \"ch4-requirements.txt\"\n",
    "\n",
    "# ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58WB13Jx3rQm",
    "outputId": "9af6cd3f-771e-4807-d041-bb8a3290bea1"
   },
   "outputs": [],
   "source": [
    "# use tensorflow 2.4.0 for this notebook\n",
    "# !pip install tensorflow==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KN6N85ah8VXf"
   },
   "outputs": [],
   "source": [
    "#Importing\n",
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mr1YXudk8Vti",
    "outputId": "4634f5ee-9c9d-4a32-9118-1845b6c43b7f"
   },
   "outputs": [],
   "source": [
    "# ##obtain the dataset\n",
    "# import os\n",
    "# try :\n",
    "#     from google.colab import files\n",
    "#     import tensorflow as tf\n",
    "#     dataset = tf.keras.utils.get_file(\n",
    "#         fname=\"aclImdb.tar.gz\", \n",
    "#         origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
    "#         extract=True,\n",
    "#     )\n",
    "#     IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "# except ModuleNotFoundError :\n",
    "#     if not os.path.exists(os.getcwd()+\"\\\\Data\\\\aclImdb\") :\n",
    "#         import tensorflow as tf\n",
    "#         dataset = tf.keras.utils.get_file(\n",
    "#             fname=\"aclImdb.tar.gz\", \n",
    "#             origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
    "#             extract=True,\n",
    "#         )\n",
    "\n",
    "#         # set path to dataset\n",
    "#         IMDB_DATADIR=os.getcwd()\n",
    "#     else :\n",
    "\n",
    "#         # set path to dataset\n",
    "#         IMDB_DATADIR=os.getcwd()+\"\\\\Data\\\\aclImdb\"\n",
    "IMDB_DATADIR = \"../data/bigdata/aclImdb/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugopbOABrmne"
   },
   "source": [
    "## STEP 1: Preprocessing\n",
    "The texts_from_folder function will load the training and validation data from the specified folder and automatically preprocess it according to BERT's requirements. In doing so, the BERT model and vocabulary will be automatically downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "jELdxonN9J8v",
    "outputId": "89eaacb7-9b62-4cca-e7df-0992cea04e7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected encoding: utf-8\n",
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_folder(IMDB_DATADIR, \n",
    "                                                                       maxlen=25, \n",
    "                                                                       preprocess_mode='bert',\n",
    "                                                                       train_test_names=['train', \n",
    "                                                                                         'test'],\n",
    "                                                                       classes=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0SIaqHcslLZ"
   },
   "source": [
    "### STEP 2: Loading a pre trained BERT and wrapping it in a ktrain.learner object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90ftQ6MgAJy4",
    "outputId": "907724f8-61d3-463c-aef5-114721f15cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mccar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "# x_train = x_train[:1000]\n",
    "# y_train = y_train[:1000]\n",
    "# x_test = x_test[:1000]\n",
    "# y_test = y_test[:1000]\n",
    "model = text.text_classifier('bert', (x_train, y_train), preproc=preproc)\n",
    "learner = ktrain.get_learner(model,train_data=(x_train, y_train), val_data=(x_test, y_test), batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN6zWQgys0c_"
   },
   "source": [
    "### STEP 3: Training and Tuning the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fxdw88YjAfvF",
    "outputId": "8296ec00-3e48-4759-fc76-e118f2bd48da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Epoch 1/2\n",
      "4167/4167 [==============================] - 4439s 1s/step - loss: 0.5480 - accuracy: 0.7079 - val_loss: 0.4828 - val_accuracy: 0.7504\n",
      "Epoch 2/2\n",
      "4167/4167 [==============================] - 4460s 1s/step - loss: 0.3931 - accuracy: 0.8178 - val_loss: 0.4830 - val_accuracy: 0.7687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x264986a8e80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(2e-5, 2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "07_BERT_Sentiment_Classification_IMDB_ktrain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
