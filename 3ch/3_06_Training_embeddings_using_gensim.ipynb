{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WGPwjhbbwPT"
      },
      "source": [
        "## Training Embeddings Using Gensim\n",
        "Word embeddings are an approach to representing text in NLP. In this notebook we will demonstrate how to train embeddings using Genism. [Gensim](https://radimrehurek.com/gensim/index.html) is an open source Python library for natural language processing, with a focus on topic modeling (explained in chapter 7)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyXXFeFZ750T",
        "outputId": "09481571-dfaf-4b7b-b5ec-fc6d61675dbd"
      },
      "outputs": [],
      "source": [
        "# To install only the requirements of this notebook, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "# !pip install gensim==3.6.0\n",
        "# !pip install requests==2.23.0\n",
        "\n",
        "# ==========================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ihAJuneD750V"
      },
      "outputs": [],
      "source": [
        "# To install the requirements for the entire chapter, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "# try :\n",
        "#     import google.colab\n",
        "#     !curl https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch3/ch3-requirements.txt | xargs -n 1 -L 1 pip install\n",
        "# except ModuleNotFoundError :\n",
        "#     !pip install -r \"ch3-requirements.txt\"\n",
        "\n",
        "# ==========================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:40.863650Z",
          "start_time": "2021-04-05T21:26:40.339123Z"
        },
        "id": "TBw9OCYcYQ_n"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:40.894143Z",
          "start_time": "2021-04-05T21:26:40.865114Z"
        },
        "id": "5qWptd54ZcfV"
      },
      "outputs": [],
      "source": [
        "# define training data\n",
        "#Genism word2vec requires that a format of ‘list of lists’ be provided for training where every document contained in a list.\n",
        "#Every list contains lists of tokens of that document.\n",
        "corpus = [['dog','bites','man'], [\"man\", \"bites\" ,\"dog\"],[\"dog\",\"eats\",\"meat\"],[\"man\", \"eats\",\"food\"]]\n",
        "\n",
        "#Training the model\n",
        "model_cbow = Word2Vec(corpus, min_count=1,sg=0) #using CBOW Architecture for trainnig\n",
        "model_skipgram = Word2Vec(corpus, min_count=1,sg=1) #using skipGram Architecture for training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QjSxefPl4mh"
      },
      "source": [
        "## Continuous Bag of Words (CBOW) \n",
        "In CBOW, the primary task is to build a language model that correctly predicts the center word given the context words in which the center word appears."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:56.724662Z",
          "start_time": "2021-04-05T21:26:56.712651Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyZY8ME4lUjd",
        "outputId": "7b8bebcd-9fdb-42d2-a32c-ed64fb11b273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec<vocab=6, vector_size=100, alpha=0.025>\n",
            "['man', 'dog', 'eats', 'bites', 'food', 'meat']\n",
            "[-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
            "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
            " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
            " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
            "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
            "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
            "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
            " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
            " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
            "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
            "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
            " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
            "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
            " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
            "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
            " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
            "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
            "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
            "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
            " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
            " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
            "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
            "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
            "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
            "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n"
          ]
        }
      ],
      "source": [
        "#Summarize the loaded model\n",
        "print(model_cbow)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(model_cbow.wv.index_to_key)\n",
        "print(words)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(model_cbow.wv['dog'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:57.420196Z",
          "start_time": "2021-04-05T21:26:57.417193Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMuHv52GeuoR",
        "outputId": "638cb7b9-7a93-4da9-c691-49d07e886419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity between eats and bites: -0.01349709\n",
            "Similarity between eats and man: -0.052354358\n"
          ]
        }
      ],
      "source": [
        "#Compute similarity \n",
        "print(\"Similarity between eats and bites:\",model_cbow.wv.similarity('eats', 'bites'))\n",
        "print(\"Similarity between eats and man:\",model_cbow.wv.similarity('eats', 'man'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twhTZfPOezTU"
      },
      "source": [
        "From the above similarity scores we can conclude that eats is more similar to bites than man."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:59.635831Z",
          "start_time": "2021-04-05T21:26:59.621818Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lv0V7WofmsB",
        "outputId": "96c71e3b-9c35-4a2d-977f-b73f0d266e68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('food', 0.13887985050678253),\n",
              " ('bites', 0.13149003684520721),\n",
              " ('eats', 0.06422408670186996),\n",
              " ('dog', 0.009391166269779205),\n",
              " ('man', -0.05987630784511566)]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Most similarity\n",
        "model_cbow.wv.most_similar('meat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:59.855822Z",
          "start_time": "2021-04-05T21:26:59.841810Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA783nrSalgs",
        "outputId": "5c38c595-d4d3-4564-f416-088ab80f6e45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec<vocab=6, vector_size=100, alpha=0.025>\n"
          ]
        }
      ],
      "source": [
        "# save model\n",
        "model_cbow.save('output/model_cbow.bin')\n",
        "\n",
        "# load model\n",
        "new_model_cbow = Word2Vec.load('output/model_cbow.bin')\n",
        "print(new_model_cbow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deReLSI7mQyr"
      },
      "source": [
        "## SkipGram\n",
        "In skipgram, the task is to predict the context words from the center word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:00.517046Z",
          "start_time": "2021-04-05T21:27:00.508038Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QtUtsLglvY0",
        "outputId": "e9108e9c-c727-42e1-a574-3cd26a64f730"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec<vocab=6, vector_size=100, alpha=0.025>\n",
            "['man', 'dog', 'eats', 'bites', 'food', 'meat']\n",
            "[-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
            "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
            " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
            " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
            "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
            "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
            "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
            " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
            " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
            "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
            "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
            " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
            "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
            " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
            "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
            " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
            "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
            "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
            "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
            " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
            " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
            "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
            "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
            "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
            "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "#Summarize the loaded model\n",
        "print(model_skipgram)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(model_skipgram.wv.index_to_key)\n",
        "print(words)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(model_skipgram.wv['dog'])\n",
        "print(len(model_skipgram.wv['dog']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:02.660747Z",
          "start_time": "2021-04-05T21:27:02.642866Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YUsblEOfFWf",
        "outputId": "26a66cd2-3d89-4c7b-ef1b-a7f3df4e248e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity between eats and bites: -0.013518773\n",
            "Similarity between eats and man: -0.0523451\n"
          ]
        }
      ],
      "source": [
        "#Compute similarity \n",
        "print(\"Similarity between eats and bites:\",model_skipgram.wv.similarity('eats', 'bites'))\n",
        "print(\"Similarity between eats and man:\",model_skipgram.wv.similarity('eats', 'man'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdXVDePKnBpv"
      },
      "source": [
        "From the above similarity scores we can conclude that eats is more similar to bites than man."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:03.419546Z",
          "start_time": "2021-04-05T21:27:03.414541Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpF4qtwpmuM3",
        "outputId": "a90d8d36-5fef-44f2-d0ad-6abce255ed11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('food', 0.13887983560562134),\n",
              " ('bites', 0.13149002194404602),\n",
              " ('eats', 0.06406080722808838),\n",
              " ('dog', 0.009391166269779205),\n",
              " ('man', -0.059876300394535065)]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Most similarity\n",
        "model_skipgram.wv.most_similar('meat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:03.973454Z",
          "start_time": "2021-04-05T21:27:03.950433Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNDCEXRTnAnj",
        "outputId": "1109d578-1e2c-4311-8e04-35e58568aa56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec<vocab=6, vector_size=100, alpha=0.025>\n"
          ]
        }
      ],
      "source": [
        "# save model\n",
        "model_skipgram.save('output/model_skipgram.bin')\n",
        "\n",
        "# load model\n",
        "new_model_skipgram = Word2Vec.load('output/model_skipgram.bin')\n",
        "print(new_model_skipgram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0MiqJ_1M0mX"
      },
      "source": [
        "## Training Your Embedding on Wiki Corpus\n",
        "\n",
        "##### The corpus download page : https://dumps.wikimedia.org/enwiki/20200120/\n",
        "The entire wiki corpus as of 28/04/2020 is just over 16GB in size.\n",
        "We will take a part of this corpus due to computation constraints and train our word2vec and fasttext embeddings.\n",
        "\n",
        "The file size is 294MB so it can take a while to download.\n",
        "\n",
        "Source for code which downloads files from Google Drive: https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drive/39225039#39225039"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:58.596845Z",
          "start_time": "2021-04-05T21:27:58.585833Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLq8kxmF750d",
        "outputId": "1b71df74-bbcf-4ff9-8e8a-5723eb68519f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "file already exists, skipping download\n",
            "File at: data/en/enwiki-latest-pages-articles-multistream22.xml-p44496246p44788941.bz2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "os.makedirs('data/en', exist_ok= True)\n",
        "# this will keep changing, need to go to this URL to figure it out:\n",
        "# https://dumps.wikimedia.org/enwiki/latest/\n",
        "# file_name = \"data/en/enwiki-latest-pages-articles-multistream14.xml-p13159683p14324602.bz2\"\n",
        "# file_name = \"data/en/enwiki-latest-pages-articles-multistream-index1.txt-p1p41242.bz2\"\n",
        "file_name = \"data/en/enwiki-latest-pages-articles-multistream22.xml-p44496246p44788941.bz2\"\n",
        "file_id = \"11804g0GcWnBIVDahjo5fQyc05nQLXGwF\"\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "if not os.path.exists(file_name):\n",
        "    download_file_from_google_drive(file_id, file_name)\n",
        "else:\n",
        "    print(\"file already exists, skipping download\")\n",
        "\n",
        "print(f\"File at: {file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T08:59:17.024306Z",
          "start_time": "2021-04-03T08:59:17.022304Z"
        },
        "id": "wX1kx96JLYvt"
      },
      "outputs": [],
      "source": [
        "from gensim.corpora.wikicorpus import WikiCorpus\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.fasttext import FastText\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T09:56:14.722195Z",
          "start_time": "2021-04-03T09:56:14.705177Z"
        },
        "id": "rJgsEUmRPppc"
      },
      "outputs": [],
      "source": [
        "#Preparing the Training data\n",
        "# lemmatize has been deprecated\n",
        "# wiki = WikiCorpus(file_name, lemmatize=False, dictionary={})\n",
        "wiki = WikiCorpus(file_name, dictionary={})\n",
        "sentences = list(wiki.get_texts())\n",
        "\n",
        "#if you get a memory error executing the lines above\n",
        "#comment the lines out and uncomment the lines below. \n",
        "#loading will be slower, but stable.\n",
        "# wiki = WikiCorpus(file_name, processes=4, lemmatize=False, dictionary={})\n",
        "# sentences = list(wiki.get_texts())\n",
        "\n",
        "#if you still get a memory error, try settings processes to 1 or 2 and then run it again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsIrgt_gPQda"
      },
      "source": [
        "### Hyperparameters\n",
        "\n",
        "\n",
        "1.   sg - Selecting the training algorithm: 1 for skip-gram else its 0 for CBOW. Default is CBOW.\n",
        "2.   min_count-  Ignores all words with total frequency lower than this.<br>\n",
        "There are many more hyperparamaeters whose list can be found in the official documentation [here.](https://radimrehurek.com/gensim/models/word2vec.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:01:20.065332Z",
          "start_time": "2021-04-03T09:59:12.350872Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idmfbr_8LvoN",
        "outputId": "197ec8aa-7849-4775-8f91-7ce0d365045d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CBOW Model Training Complete.\n",
            "Time taken for training is:0.01 hrs \n"
          ]
        }
      ],
      "source": [
        "#CBOW\n",
        "start = time.time()\n",
        "word2vec_cbow = Word2Vec(sentences,min_count=10, sg=0)\n",
        "end = time.time()\n",
        "\n",
        "print(\"CBOW Model Training Complete.\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:02:10.613551Z",
          "start_time": "2021-04-03T10:02:10.585535Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMdGn08-RkhM",
        "outputId": "f0072a3f-f82d-422f-e9a0-91952d3a6d49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec<vocab=40190, vector_size=100, alpha=0.025>\n",
            "------------------------------\n",
            "Length of vocabulary: 40190\n",
            "Printing the first 30 words.\n",
            "['the', 'of', 'and', 'in', 'to', 'was', 'on', 'as', 'is', 'for', 'by', 'with', 'he', 'at', 'from', 'that', 'his', 'it', 'an', 'also', 'were', 'which', 'are', 'first', 'her', 'this', 'has', 'she', 'be', 'references']\n",
            "------------------------------\n",
            "Length of vector: 100\n",
            "[ 2.219304   -0.8354919   2.6662729  -2.4509525   2.9505837  -1.878043\n",
            "  0.06650275 -0.9594213   0.9108776   2.0968235  -0.48863474 -3.2809408\n",
            " -1.4194704   0.64886856  1.7247549  -0.10405306  1.7054323   0.26500842\n",
            " -2.6201446  -0.10065644  1.7148116  -1.6619455  -0.8734362  -1.324647\n",
            " -0.43044254  1.4404098  -0.8076793   0.7346869   2.146768   -2.0302885\n",
            "  1.1566433   1.562745    1.796327    1.3882915  -1.0332848  -2.7455528\n",
            "  2.944826    0.6361229   1.995394   -4.32989    -3.4562297   2.2285547\n",
            "  1.339047   -1.2293513  -0.32261008 -2.717089   -1.3406433   2.6678302\n",
            " -1.0551729   1.2701708  -1.7687007  -1.0852286   0.10473851 -2.0591846\n",
            "  2.0687785  -4.0941043  -1.0622346   0.6262164   0.5276296  -1.0950333\n",
            " -2.816982    2.9720094  -1.1462209   1.4557447   2.990514    0.48893318\n",
            "  1.5813593   0.4400288  -1.4147421   2.423657   -0.52922124  2.3356216\n",
            " -2.3586147   3.7672284  -1.0560219   1.814833    1.3420217  -2.2803597\n",
            " -2.3410661  -1.0486562   0.75069416 -1.8881654  -4.011446    0.49119118\n",
            " -2.6773226  -0.2916659   3.464206   -3.4734328   1.1988882   2.5303428\n",
            "  1.0666542   2.6341646  -2.2868094   1.3052481   0.29970428  0.52458966\n",
            " -1.8574969   0.33129996  0.9016011  -3.6616113 ]\n",
            "------------------------------\n",
            "Similarity between film and drama: 0.562227\n",
            "Similarity between film and tiger: 0.081459224\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "#Summarize the loaded model\n",
        "print(word2vec_cbow)\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(word2vec_cbow.wv.index_to_key)\n",
        "print(f\"Length of vocabulary: {len(words)}\")\n",
        "print(\"Printing the first 30 words.\")\n",
        "print(words[:30])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(f\"Length of vector: {len(word2vec_cbow.wv['film'])}\")\n",
        "print(word2vec_cbow.wv['film'])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Compute similarity \n",
        "print(\"Similarity between film and drama:\",word2vec_cbow.wv.similarity('film', 'drama'))\n",
        "print(\"Similarity between film and tiger:\",word2vec_cbow.wv.similarity('film', 'tiger'))\n",
        "print(\"-\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:02:16.109851Z",
          "start_time": "2021-04-03T10:02:15.257052Z"
        },
        "id": "rXrDOrKskcHX"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "from gensim.models import Word2Vec, KeyedVectors   \n",
        "word2vec_cbow.wv.save_word2vec_format('word2vec_cbow.bin', binary=True)\n",
        "\n",
        "# load model\n",
        "# new_modelword2vec_cbow = Word2Vec.load('word2vec_cbow.bin')\n",
        "# print(word2vec_cbow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:08:27.736688Z",
          "start_time": "2021-04-03T10:02:19.197708Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX0U0CbQOK30",
        "outputId": "a86c4a77-0c9f-464b-d283-9808fa434b72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SkipGram Model Training Complete\n",
            "Time taken for training is:0.02 hrs \n"
          ]
        }
      ],
      "source": [
        "#SkipGram\n",
        "start = time.time()\n",
        "word2vec_skipgram = Word2Vec(sentences,min_count=10, sg=1)\n",
        "end = time.time()\n",
        "\n",
        "print(\"SkipGram Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:09:06.406929Z",
          "start_time": "2021-04-03T10:09:06.383908Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXnY9YInSvnI",
        "outputId": "b151eb0c-2870-4df2-d38f-2cc4613d2f7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec<vocab=40190, vector_size=100, alpha=0.025>\n",
            "------------------------------\n",
            "Length of vocabulary: 40190\n",
            "Printing the first 30 words.\n",
            "['the', 'of', 'and', 'in', 'to', 'was', 'on', 'as', 'is', 'for', 'by', 'with', 'he', 'at', 'from', 'that', 'his', 'it', 'an', 'also', 'were', 'which', 'are', 'first', 'her', 'this', 'has', 'she', 'be', 'references']\n",
            "------------------------------\n",
            "Length of vector: 100\n",
            "[ 0.32331878  0.5790854   0.43830907  0.20141493  0.40692985 -0.9307328\n",
            "  0.38431042  0.47711086 -0.44711447 -0.27486363 -0.03668171 -0.35193586\n",
            "  0.11449455 -0.0292649   0.02325125 -0.18134807  0.3840576  -0.6193043\n",
            " -0.41114882 -0.218237    0.21878621 -0.21981032  0.14389041 -0.05950952\n",
            "  0.13657631  0.37229234 -0.61114234  0.18194164 -0.1850214   0.06693834\n",
            "  0.82910615 -0.4441088   0.36599264 -0.0019779  -0.2821699  -0.19844653\n",
            "  0.34508672  0.01054496 -0.26363865 -0.25678846 -0.08147195  0.15462402\n",
            " -0.15726426 -0.01737205 -0.22792116 -0.37410778 -0.37628466  0.04001839\n",
            " -0.4821334   0.20702335  0.45608982 -0.32124573 -0.44137335 -0.3296108\n",
            "  0.3512095  -0.34397483 -0.6436981   0.13268866  0.10476562 -0.17032321\n",
            "  0.24361494  0.3178388  -0.14455295  0.21332672  0.26984137  0.42351285\n",
            " -0.11251837 -0.35668188 -0.30024654  0.12951536 -0.37476063  0.53381157\n",
            "  0.4043369   0.88016003  0.17747219 -0.3310836   0.22371975 -0.0946264\n",
            " -0.5699127   0.12564135 -0.03659636  0.16551787 -0.36601114  0.54120964\n",
            "  0.07494999  0.4841925   0.27776024 -0.07214247  0.09756988  0.4791104\n",
            "  0.7094821   0.10169122 -0.77741134 -0.09066202  0.12562971 -0.08991127\n",
            " -0.83485264  0.5075075   0.5903247   0.22813495]\n",
            "------------------------------\n",
            "Similarity between film and drama: 0.66206956\n",
            "Similarity between film and tiger: 0.33024338\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "#Summarize the loaded model\n",
        "print(word2vec_skipgram)\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(word2vec_skipgram.wv.index_to_key)\n",
        "print(f\"Length of vocabulary: {len(words)}\")\n",
        "print(\"Printing the first 30 words.\")\n",
        "print(words[:30])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(f\"Length of vector: {len(word2vec_skipgram.wv['film'])}\")\n",
        "print(word2vec_skipgram.wv['film'])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Compute similarity \n",
        "print(\"Similarity between film and drama:\",word2vec_skipgram.wv.similarity('film', 'drama'))\n",
        "print(\"Similarity between film and tiger:\",word2vec_skipgram.wv.similarity('film', 'tiger'))\n",
        "print(\"-\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:09:09.947695Z",
          "start_time": "2021-04-03T10:09:09.076901Z"
        },
        "id": "o8U7bfPSVB04"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "word2vec_skipgram.wv.save_word2vec_format('word2vec_sg.bin', binary=True)\n",
        "\n",
        "# load model\n",
        "# new_model_skipgram = Word2Vec.load('model_skipgram.bin')\n",
        "# print(model_skipgram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kExlA8kfrKml"
      },
      "source": [
        "## FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:16:31.271764Z",
          "start_time": "2021-04-03T10:09:16.592670Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPd2VhMEk8gL",
        "outputId": "e4ed35b2-4338-4341-e150-68763015d3af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FastText CBOW Model Training Complete\n",
            "Time taken for training is:0.03 hrs \n"
          ]
        }
      ],
      "source": [
        "#CBOW\n",
        "start = time.time()\n",
        "fasttext_cbow = FastText(sentences, sg=0, min_count=10)\n",
        "end = time.time()\n",
        "\n",
        "print(\"FastText CBOW Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:16:31.287283Z",
          "start_time": "2021-04-03T10:16:31.273765Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlQFl8-Zsost",
        "outputId": "49e9cf5f-58c2-4cb6-89e1-c70eb0686c37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FastText<vocab=40190, vector_size=100, alpha=0.025>\n",
            "------------------------------\n",
            "Length of vocabulary: 40190\n",
            "Printing the first 30 words.\n",
            "['the', 'of', 'and', 'in', 'to', 'was', 'on', 'as', 'is', 'for', 'by', 'with', 'he', 'at', 'from', 'that', 'his', 'it', 'an', 'also', 'were', 'which', 'are', 'first', 'her', 'this', 'has', 'she', 'be', 'references']\n",
            "------------------------------\n",
            "Length of vector: 100\n",
            "[  0.49952504   3.9394662    5.977159    -1.0057093   -3.5727525\n",
            "   0.61577755   0.06744188   0.02997959   4.488094     0.9230299\n",
            "   0.7005552    0.2315209   -2.176848     0.81778026  -1.2810814\n",
            "   0.3064063    1.4155692   -1.1717366   -0.5766693    4.689038\n",
            "  -2.199509     3.9081602    0.41604897   5.528003     1.2504398\n",
            "   1.3626084   -2.6119337    6.7407537   -1.6044441    0.16712666\n",
            "   3.2573516    1.6671691    2.1402783   -2.6542192   -1.5304126\n",
            "  -0.9959465    0.358603     1.7427573    1.713649     2.8426118\n",
            "  -3.6570632   -0.96193963   1.041286    -4.174572     0.61696625\n",
            "  -4.305218    -0.56435764   0.15420932  -0.45147145   0.7296288\n",
            "  -0.4569608   -0.8571524   -6.1070437   -1.4351301    1.2617091\n",
            "  -1.7342238   -1.1592419    0.27956912   6.5355515    1.4238816\n",
            "  -2.3918774   -0.94803655   2.6824746    1.309679     3.676187\n",
            "  -1.6926116   -1.5190603   -1.6724075   -0.6931692    3.1738672\n",
            "  -1.9693916    8.674293     3.1333702   -1.4668152  -11.305783\n",
            "  -2.8570116   -0.5883521    1.4240457   -0.9648703   -1.5039048\n",
            "  -1.9905883    1.0924354    1.1927185    3.5497718   -1.6138653\n",
            "  -2.3681557    0.26681495  -5.3048863   -0.08355647   1.5399266\n",
            "   4.8147287   -0.5656145   -7.0224133    1.4168216   -0.1674599\n",
            "  -1.1451378    0.7938287    1.6427379   -2.6224706    0.12728515]\n",
            "------------------------------\n",
            "Similarity between film and drama: 0.6093677\n",
            "Similarity between film and tiger: 0.14549868\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "#Summarize the loaded model\n",
        "print(fasttext_cbow)\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(fasttext_cbow.wv.index_to_key)\n",
        "print(f\"Length of vocabulary: {len(words)}\")\n",
        "print(\"Printing the first 30 words.\")\n",
        "print(words[:30])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(f\"Length of vector: {len(fasttext_cbow.wv['film'])}\")\n",
        "print(fasttext_cbow.wv['film'])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Compute similarity \n",
        "print(\"Similarity between film and drama:\",fasttext_cbow.wv.similarity('film', 'drama'))\n",
        "print(\"Similarity between film and tiger:\",fasttext_cbow.wv.similarity('film', 'tiger'))\n",
        "print(\"-\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:28:28.771383Z",
          "start_time": "2021-04-03T10:16:31.289284Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgSOxsNklAvh",
        "outputId": "07242007-88e5-47c2-dbb7-7378e91c045c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FastText SkipGram Model Training Complete\n",
            "Time taken for training is:0.04 hrs \n"
          ]
        }
      ],
      "source": [
        "#SkipGram\n",
        "start = time.time()\n",
        "fasttext_skipgram = FastText(sentences, sg=1, min_count=10)\n",
        "end = time.time()\n",
        "\n",
        "print(\"FastText SkipGram Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:28:28.803412Z",
          "start_time": "2021-04-03T10:28:28.773386Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFiTAP0PsQwi",
        "outputId": "a376e4ff-bf30-4af8-e192-979ab2a09622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FastText<vocab=40190, vector_size=100, alpha=0.025>\n",
            "------------------------------\n",
            "Length of vocabulary: 40190\n",
            "Printing the first 30 words.\n",
            "['the', 'of', 'and', 'in', 'to', 'was', 'on', 'as', 'is', 'for', 'by', 'with', 'he', 'at', 'from', 'that', 'his', 'it', 'an', 'also', 'were', 'which', 'are', 'first', 'her', 'this', 'has', 'she', 'be', 'references']\n",
            "------------------------------\n",
            "Length of vector: 100\n",
            "[-1.3109466e-01  7.1749598e-01  6.6718823e-01 -6.4493126e-01\n",
            "  3.0446741e-01  3.5411862e-01  3.4830281e-01  4.4338515e-01\n",
            " -3.0940580e-01 -8.1276399e-01 -9.2982106e-02 -1.8297681e-01\n",
            " -1.6826162e-01 -1.3484047e-02 -2.5378418e-01 -2.0926823e-01\n",
            "  4.9818209e-01  3.6550432e-02 -7.5924933e-01 -2.0646293e-02\n",
            " -2.9643467e-01  5.3815728e-01  9.8732240e-02  7.7871017e-02\n",
            " -1.8261248e-01 -1.2075171e-01 -3.8744116e-01 -2.5337830e-01\n",
            " -1.1243188e-01 -1.3551758e-01 -9.3174815e-02 -2.9903981e-01\n",
            "  2.8691188e-01 -3.3972341e-01 -1.7674230e-01 -4.6721286e-01\n",
            "  3.8444540e-01  5.1899862e-01 -3.0457595e-01 -1.3325375e-01\n",
            "  2.2776479e-01  3.8030759e-02 -2.5510150e-01  3.9685774e-01\n",
            " -1.8305499e-02 -2.7873459e-01 -3.1155959e-01  2.2608300e-01\n",
            " -8.3570117e-01  3.6830428e-01  2.5325581e-01 -5.9113377e-01\n",
            " -6.3707012e-01 -5.2103883e-01 -3.8538769e-01 -1.6999066e-01\n",
            " -5.2717794e-02 -7.3111422e-02  2.4839009e-01 -5.7879770e-01\n",
            " -2.8736389e-01 -1.5137221e-01 -6.7176528e-02  5.1170516e-01\n",
            " -9.1413215e-02  4.2719090e-01 -7.3283666e-01 -2.3816700e-01\n",
            "  3.4492701e-01  7.7845350e-02 -1.4937574e-01  2.5096428e-01\n",
            "  7.5465661e-01  3.1427157e-01 -2.1179670e-01 -5.6429344e-01\n",
            "  1.5279822e-01  2.0089111e-01  1.8197194e-01  2.1492162e-01\n",
            " -4.9996960e-01  4.5102943e-02  5.0474334e-01  2.2027412e-02\n",
            " -3.5127887e-01 -1.1528087e+00  2.5230202e-01 -2.7959412e-01\n",
            "  1.8687560e-01  5.2119833e-01  4.2768553e-01  2.4568887e-01\n",
            "  7.8457087e-02  9.3432789e-04  3.6922038e-01  3.1380409e-01\n",
            "  2.0535740e-01 -8.1947155e-02  2.5972378e-01  5.1292813e-01]\n",
            "------------------------------\n",
            "Similarity between film and drama: 0.66015524\n",
            "Similarity between film and tiger: 0.36713526\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "#Summarize the loaded model\n",
        "print(fasttext_skipgram)\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(fasttext_skipgram.wv.index_to_key)\n",
        "print(f\"Length of vocabulary: {len(words)}\")\n",
        "print(\"Printing the first 30 words.\")\n",
        "print(words[:30])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(f\"Length of vector: {len(fasttext_skipgram.wv['film'])}\")\n",
        "print(fasttext_skipgram.wv['film'])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Compute similarity \n",
        "print(\"Similarity between film and drama:\",fasttext_skipgram.wv.similarity('film', 'drama'))\n",
        "print(\"Similarity between film and tiger:\",fasttext_skipgram.wv.similarity('film', 'tiger'))\n",
        "print(\"-\"*30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oArMIJzYOmUR"
      },
      "source": [
        "#### An interesting obeseravtion if you noticed is that CBOW trains faster than SkipGram in both cases.\n",
        "We will leave it to the user to figure out why. A hint would be to refer the working of CBOW and skipgram."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "06_Training_embeddings_using_gensim.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
